{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q4gSqDnOaJ7W"
   },
   "source": [
    "<h2 align=center> Named Entity Recognition (NER) using LSTMs with Keras</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below was adapted from: https://www.coursera.org/learn/named-entity-recognition-\n",
    "lstm-keras-tensorflow/ungradedLti/mbo1Q/named-entity-recognition-using-lstms-with-keras,\n",
    "accessed 17/5/2020."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input data must be in the following format:\n",
    "\n",
    "Sentence #,Word,POS,Tag\n",
    "Sentence: 1,Finishing,,O\n",
    ",Pig,NN,O\n",
    ",Stockperson,NN,O\n",
    "\n",
    "And saved as filename.csv. NN stands for noun."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fdo8oAodagwo"
   },
   "source": [
    "### Task 1: Project Overview and Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "oLK7Y1jiNXDa",
    "outputId": "0f319464-ee49-4035-f6fb-8396f488c41f"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras\n",
    "print('Tensorflow version:', tf.__version__)\n",
    "print('GPU detected:', tf.config.list_physical_devices('GPU'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 363
    },
    "colab_type": "code",
    "id": "mCKmz4SAbI_m",
    "outputId": "a03b1aed-dc60-4f03-cb06-19e440fa6367",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"filename.csv\", encoding=\"latin1\")\n",
    "data = data.fillna(method=\"ffill\")\n",
    "data.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "riOztP-8NXHT",
    "outputId": "200d251b-17c9-451b-9e96-523f458be47e",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Unique words in corpus:\", data['Word'].nunique())\n",
    "print(\"Unique tags in corpus:\", data['Tag'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "words = list(set(data[\"Word\"].values))\n",
    "words.append(\"ENDPAD\")\n",
    "num_words = len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tags = list(set(data[\"Tag\"].values))\n",
    "num_tags = len(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M9D9JEzUbdnS"
   },
   "source": [
    "### Task 3: Retrieve Sentences and Corresponsing Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "VdJst_g5NYY_"
   },
   "outputs": [],
   "source": [
    "class SentenceGetter(object):\n",
    "    def __init__(self, data):\n",
    "        self.n_sent = 1\n",
    "        self.data = data\n",
    "        self.empty = False\n",
    "        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n",
    "                                                           s[\"POS\"].values.tolist(),\n",
    "                                                           s[\"Tag\"].values.tolist())]\n",
    "        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n",
    "        self.sentences = [s for s in self.grouped]\n",
    "    \n",
    "    def get_next(self):\n",
    "        try:\n",
    "            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n",
    "            self.n_sent += 1\n",
    "            return s\n",
    "        except:\n",
    "            return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "nMUQLppspkPj"
   },
   "outputs": [],
   "source": [
    "getter = SentenceGetter(data)\n",
    "sentences = getter.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 434
    },
    "colab_type": "code",
    "id": "GhiSTt2UdzYC",
    "outputId": "95d275f6-f386-46d8-a583-2861d64c6b72"
   },
   "outputs": [],
   "source": [
    "sentences[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ldhuogX4eHE4"
   },
   "source": [
    "### Task 4: Define Mappings between Sentences and Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "SvENHO18pkaQ"
   },
   "outputs": [],
   "source": [
    "word2idx = {w: i + 1 for i, w in enumerate(words)}\n",
    "tag2idx = {t: i for i, t in enumerate(tags)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zXzE0MdsemCH"
   },
   "source": [
    "### Task 5: Padding Input Sentences and Creating Train/Test Splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "id": "R44g5T7NYp_H",
    "outputId": "135a85a6-7a85-4b16-a8eb-3ad7bd4da5b6"
   },
   "outputs": [],
   "source": [
    "plt.hist([len(s) for s in sentences], bins=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "FS4u3CRkpkc1"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "max_len = 50\n",
    "\n",
    "X = [[word2idx[w[0]] for w in s] for s in sentences]\n",
    "X = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value=num_words-1)\n",
    "\n",
    "y = [[tag2idx[w[2]] for w in s] for s in sentences]\n",
    "y = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2idx[\"O\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "q7VfnnkXpkfS"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "P-r4PR85hpoF"
   },
   "source": [
    "### Task 6: Build and Compile a Bidirectional LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "Y2vM7IkXpkiH"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras import Model, Input\n",
    "from tensorflow.keras.layers import LSTM, Embedding, Dense\n",
    "from tensorflow.keras.layers import TimeDistributed, SpatialDropout1D, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 330
    },
    "colab_type": "code",
    "id": "Aee3mCZ3pkkv",
    "outputId": "b7fb911b-21d1-43e6-adc9-bb2d8bdfb921"
   },
   "outputs": [],
   "source": [
    "input_word = Input(shape=(max_len,))\n",
    "model = Embedding(input_dim=num_words, output_dim=50, input_length=max_len)(input_word)\n",
    "model = SpatialDropout1D(0.1)(model)\n",
    "model = Bidirectional(LSTM(units=100, return_sequences=True, recurrent_dropout=0.1))(model)\n",
    "out = TimeDistributed(Dense(num_tags, activation=\"softmax\"))(model)\n",
    "model = Model(input_word, out)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "kOBpQg26pkqh"
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\",\n",
    "              loss=\"sparse_categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "My0tL0cciMXQ"
   },
   "source": [
    "### Task 7: Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Only required once\n",
    "#!pip install livelossplot==0.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import livelossplot\n",
    "import tensorflow.keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#from livelossplot.tf_keras import PlotLossesCallback # Callbacks not working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 536
    },
    "colab_type": "code",
    "id": "Q9HWH06Ypkxh",
    "outputId": "e83ba281-0c14-4bca-dacb-cb708edacba5"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "chkpt = ModelCheckpoint(\"model_weights.h5\", monitor='val_loss',verbose=1, save_best_only=True, save_weights_only=True, mode='min')\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=1, verbose=0, mode='max', baseline=None, restore_best_weights=False)\n",
    "\n",
    "#callbacks = [PlotLossesCallback(), chkpt, early_stopping]\n",
    "\n",
    "history = model.fit(\n",
    "    x=x_train,\n",
    "    y=y_train,\n",
    "    validation_data=(x_test,y_test),\n",
    "    batch_size=32, \n",
    "    epochs=5,\n",
    "    #callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2nwnnF0ziU3B"
   },
   "source": [
    "### Task 8: Evaluate Named Entity Recognition Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "6euqX7UHplG7",
    "outputId": "7222c24c-52c5-454b-a5d4-03d6df4173f0"
   },
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 920
    },
    "colab_type": "code",
    "id": "Tyg4mKOVplJ-",
    "outputId": "59e897c3-cb77-4dc2-a239-dea2c94eec42"
   },
   "outputs": [],
   "source": [
    "i = np.random.randint(0, x_test.shape[0]) #659\n",
    "p = model.predict(np.array([x_test[i]]))\n",
    "p = np.argmax(p, axis=-1)\n",
    "y_true = y_test[i]\n",
    "print(\"{:15}{:5}\\t {}\\n\".format(\"Word\", \"True\", \"Pred\"))\n",
    "print(\"-\" *30)\n",
    "for w, true, pred in zip(x_test[i], y_true, p[0]):\n",
    "    print(\"{:15}{}\\t{}\".format(words[w-1], tags[true], tags[pred]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "NER.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
